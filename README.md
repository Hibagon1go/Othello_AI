# Othello_AI

# ターミナル等で動くオセロゲーム & NN(ニューラルネット)とGA(遺伝的アルゴリズム)を用いたオセロAI

## AIの動作
各盤面の状況から特徴量を抽出し(どの特徴量を抽出するかは事前にこちらで設定)、NNを通じて盤面評価値を決定する。  
現在打てるマスのうち、打つことで最も盤面評価値が大きくなるような手を打つ。  
盤面評価値の決め方が大きな鍵を握るが、それを学習するのにGAを用いる。

## NNの内容
今回、特徴量としては
- 角マスの黒と白の数の差
- 真ん中2×2の黒と白の数の差
- 真ん中4×4の黒と白の数の差
- 全体の黒と白の数の差
- 相手が打てるマスの数  

の5つを採用した。  
これを入力とし、3層のニューラルネットを組んだ。

入力層(5ノード)  -> 隠れ層(10ノード)  -> 出力層(1ノード)  -> 盤面評価値  
- 入力層から隠れ層への伝達 : 10×5の重み行列
- 隠れ層から出力層への伝達 : 1×10の重み行列
- 出力値から盤面評価値への変換 : シグモイド関数
            
## GAの内容

0. 初期世代の個体を25個体生成(各個体、乱数により重み行列を生成)  

1. 現世代の個体同士を総当たりで戦わせて勝敗をつける。  
2. 勝敗に基づき、以下のような形で次世代の個体25個体を生成する。  
   - 強さ上位2個体はエリート個体として、次世代にそのまま残す。
   - エリート2個体を親とし、それらを交叉(重み行列の一部をスワップする)して、エリートの子供の個体を2個体生成し、次世代に残す。
   - エリートでない個体から、強い個体が選ばれやすいように傾斜をかけながら5個体ランダムに選び、次世代に残す。
   - 現世代から、強い個体が選ばれやすいように傾斜をかけながら親を選び、それらの子供を作る。(16個体)
3. 次世代の個体に対し、1に戻って繰り返す。  


## オセロAIとのプレイ方法(後手を選ぶのを推奨)
VS_NN_GA_1フォルダ内のplay_vs_NN_GA_1.pyを実行すればプレイできます。(操作性とかは悪いです。また、白以外の背景の場所(ターミナルとか)でプレイする場合、●と○が逆に見えてしまいます。）

## 備考
考え方だけ調べて、ほぼほぼ自力で実装しました。(だからコードはかなり汚いです...)  
学習はGoogle Colaboratoryを利用しました。  
-> NN_GA_learningフォルダ内のNN_and_GA_Learning.ipynbを実行しました。  

参考にした記事や動画は以下です。  
https://qiita.com/shiracamus/items/f03127819fff0f1a4349  
https://qiita.com/hmarf/items/e33a4146128e65c59cbd#nn  
https://youtu.be/D7rjGRoiCeM  
